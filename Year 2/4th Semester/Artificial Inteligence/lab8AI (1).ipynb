{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics==5.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZPUNYIAAjf6",
        "outputId": "517943c1-3d83-4eed-af05-2b2646aca85e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-ai-textanalytics==5.2.0 in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-textanalytics==5.2.0) (1.34.0)\n",
            "Requirement already satisfied: msrest>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-textanalytics==5.2.0) (0.7.1)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-textanalytics==5.2.0) (1.1.28)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-textanalytics==5.2.0) (4.13.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0) (2025.4.26)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0) (0.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (2.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.7.0->azure-ai-textanalytics==5.2.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "\n",
        "os.environ['VISION_KEY'] = \"1iBEgn3st92HytC7Cc9RAnqYi0H2QBMCQCjYPlxgBAGDDLGrKwX1JQQJ99BEAC5RqLJXJ3w3AAAAACOG2ezo\"\n",
        "os.environ['VISION_ENDPOINT'] = \"https://lab8aitextminingsentiments.openai.azure.com/\"\n",
        "\n",
        "subscription_key = os.environ[\"VISION_KEY\"]\n",
        "endpoint = os.environ[\"VISION_ENDPOINT\"]\n",
        "\n",
        "client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(subscription_key))"
      ],
      "metadata": {
        "id": "xGcmVTR3DKIM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "crtDir = os.getcwd()\n",
        "fileName = os.path.join(crtDir, 'data', 'reviews_mixed.csv')\n",
        "print(fileName)\n",
        "\n",
        "data = []\n",
        "with open(fileName) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    headers = next(csv_reader)\n",
        "    text_index = headers.index(\"Text\")\n",
        "\n",
        "    for row in csv_reader:\n",
        "        data.append(row[text_index])\n",
        "\n",
        "def chunks(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "batch_size = 10\n",
        "for batch in chunks(data, batch_size):\n",
        "    result = client.analyze_sentiment(batch, show_opinion_mining=True)\n",
        "    docs = [doc for doc in result if not doc.is_error]\n",
        "\n",
        "    for idx, doc in enumerate(docs):\n",
        "        print(f\"\\nText: {batch[idx]}\")\n",
        "        print(f\"Overall sentiment: {doc.sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X61fVMONF8NM",
        "outputId": "5b25da2b-0ef4-41e9-c6ed-c963d34580d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/reviews_mixed.csv\n",
            "\n",
            "Text: The rooms are extremely small, practically only a bed.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Room safe did not work.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Mattress very comfortable.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Very uncomfortable, thin mattress, with plastic cover that rustles every time you move.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: No bathroom in room\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The bed was soooo comfy.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: someone must have been smoking in the room next door.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The bed is very comfortable.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Very spacious rooms, quiet and very comfortable.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: For 3 people in a bedroom the sofa bed is a bit unconfortable.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Lights in the common room were too dim.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Air conditioning working fine.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: So if you're the type that likes to let water run a bit before getting wet or it takes a minute to figure out how to make it hot, you're gonna get wet.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: the windows are only single glazed so the heat could escape- although to be fair it was -6 outside!\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Terrible, small cubbyholes, which are marketed as rooms.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Corridors filthy\n",
            "Room filthy\n",
            "Electrical cables in room not safe\n",
            "Whole building smelly\n",
            "Shower repulsive\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: walls seem to have no sound insulation\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The gym was very small and basic\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The mattresses were too \"springy\" and uncomfortable.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: very light and the comfy of the bed was unbeatable.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Shows some wear and tear.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Some thinks didnt work well : air, tv , open windows,\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Microwave needed!\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Room wasn't cleaned or bed made up\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The room had cable TV, a safe, an iron, a hairdryer and free coffee & tea in the downstairs area.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The heat in the room fluctuated -- at times it felt a little draft, and on my last night, the fan was really loud.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: #NAME?\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The building was under renovation,\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The water pressure was not that strong in the shower.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Room too small to open suitcase.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: no elevator might be a challenge for some people\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Pay extra.. :( Room was tiny\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: and hip and CLEAN!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Comfortable bed and selection of pillows.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The TV was not working.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The walk up 4 stories\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Hallways to room stale and didn't feel clean.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: there was a building under construction across the road which was extremely noisy throughout the day.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Bathtub not clean.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Hot water was abundant and the A/C (window unit) was ice cold - Excellent!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Access to fitness facilities, especially the pool was a real value added.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Barely room for anything else than sleep.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Lift was a bit of a pain with card access.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Could have used a little more counter room in bath and we didn't think the restaurant looked very inviting compared to the rest of the hotel.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The bed was highly uncomfortable, although the engineer fixed it\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The memory foam mattress - we all agreed the best night's sleep in a hotel EVER...\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Toilet paper wasn't replaced everyday!\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The extra beds are not the greatest (a futon and a sleeper couch)\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Room was extremely cramped.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Shower cap n sanitary bags not available in the room.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: it was freezing cold in my room for the night I stayed.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Outside seating was lovely\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The heating was unbelievably noisy during the night.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: bed, smell.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bathroom area large would have been nice with a bathtub.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Shared restrooms do not support many rooms and/or many people.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Stiff feel to the place- no amenities.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Lovely room, bed was so comfortable!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Every 15 minutes door were slamming & lights on.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: After that time, mostly quiet apart from some door slamming by other guests.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The top of the window was then covered by the dirty blind.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Detest the glass \"door\" if shower/tub .. with?\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: this was expected, clean towels and room cleaned every day.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Barely a few degrees warmer than outside during winter, so I had to rug up and wear shoes to use the toilet.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: ac was terrible\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: More plug outlets with surge protectors.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Just to give you an idea: the shutters of the windows were not working, did not go neither up or down - just hanging down only one side and the other up....\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The phone in my room was not working.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Elevators are slow, very long lines.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Location anda facilities\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: There was also  garbage in our kitchen - there were isntant coffee packages left from previous customers.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Amazing facilities.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Only one elevator ,\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Room was very spacious\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The bathroom is dirty.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Roof terrace great\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: No tea or coffee making facilities in the rooms\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: the room had aircon and we had earplugs and slept soundly.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Also, when the bright bathroom lights are turned on, it lights up the whole hotel room, shining thru the frosted glass panels.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The Bed was SUPER COMFY !\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Bathroom was extra small,\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Rooms are cosy with great temperature control.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Facilities were very clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: only if you don't mind stains in your bed sheets or cockroaches in your (shared) bathroom.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The bathroom functioned o.k.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Poor TV picture and channel selection.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: No elevator.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: essential gym to allow for some workout.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Rooms quite small for price, especially if you use a travel cot.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: room was not at all inviting.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Wifi connected\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Everything was very clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Windows haven't been cleaned for years (if ever).\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Showers could do with some renovations - they seem clean,\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Only cold water came out.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: the Persian decor is so half-hearted it - I'd take down the 5 lengths of Turkish bunting lanterns above the glass roofed bar or cover the whole area with them - 30 more (!)\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The toilet ran until you jiggled the handle.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The bed was terrible and not comfortable at all\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Mattresses and linens were all great.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: No wardrobe, no space for luggage, no towel change, walls are not sound proof thus very noisy.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The elevators were fast - never we had to wait long for a one.On 15th floor the city noise was not bothering at all and after the whole day walking around we were sleeping execellent.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Has most things you need.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bed was not a full size 2,40 cm long bed, they were smaller.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: very spartan.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Room extremely small.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: No walls mean oher guests being loud at all hrs.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Very nice rooftop terrace, and gym.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Wallpaper is peeking off in places.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Insufficient and hard to reach plugs to charge devices.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Mouse in the room,\n",
            "No Wifi,\n",
            "No cleaning service in 3 days,\n",
            "No elevators,\n",
            "Doors to outside of hotel didn't lock anymore,\n",
            "On main avenue, with constructions, one of our room was pretty loud.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: No bath, only a shower, and I requested 2 queen size beds\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: I called and they just hadn't received the shipment of clean towels.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The room was clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: I don't mind the small space,\n",
            "just would have liked a bit more \"style.\"\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: King Room was spacious with plenty of room to spread out and unpack, especially awesome for an extended stay.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Hotel was very clean and had character.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: on HVAC vent.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: We just had to place our luggage on the floor.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Unclean bathrooms.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Only negative was the old and very loud air conditioning in the rooms.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: there was dust and tissue under the bed.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The bed was very comfy & the room spacious.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: No air conditioning.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bath and shower were in poor condition and didn''t hold the water.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: I was told I would have two double beds.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bathroom and shower were very good!, lighting as well.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Rooms too small.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Our room had left over garbage from whomever stayed there prior.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The floor was not very clean.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Very comfortable beds.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The only area of improvement would be the fitness center.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The pool is the best!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: good soundproofing to windows), great showerroom with excellent hot shower, good air con, free wifi and coffee maker.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: 5 star qualiity towels and linen.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: we only had 7 channels which four of them werent in english.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: It's much more potent and pleasant than\n",
            "any Febreeze scent.\n",
            "\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Some have small televisions, flat screen, or the old 1990's tube, as well as, some of the rooms do not have that amenity.I usually book a double room, which thus far comes with a window and is a bit more spacious.The single rooms are much smaller, yet comfortable.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Room was large for my family of 4 adults.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: My room was pretty soulless, although it did have a great view.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The room itself was very clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: My room was immaculate and smelled so fresh and clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: quiet place.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The room was a nice size, big enough for both my and my friend's huge suitcases to fit on the floor and for us to still move around.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The hotel was very clean.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: No kettle, had to use a coffee maker to boil water for tea which was tricky as it had to be rinsed through many times.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Rooms were spotless and classy.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The front entrance could use some curb appeal.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bathroom was way too retro.......shower was very poor... no hand shower, poor water pressure and way too narrow.......It also had a plastic curtain which for a $650 dollar hotel room is way too nasty.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: extra small rooms.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Poor beds quality, very very noisy : would have been the same if we would have no windows.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The bathrooms have frosted glass walls,not private at all.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Rooms are cold and you can't adjust the temperature and also heating works only a few hours in the morning.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: very loud construction noise out front of our window.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The room was interior so no traffic noise.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Room was noisy and cold.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The air-con was too noisy to leave on for too long.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: still easy to reach.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The front door didn't work so we had to pry it open.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: clean and tidy.\n",
            "\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The bed is really terrible,especially the blanket is heavy and terrible terrible quality.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Bathroom sink tap leaked and aircon didn't work properly\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: We didn't like the mouse in the room.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Decent room\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Loved the elegant art deco ambience.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Broken tiles in shower.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: In the shower it was turned down as cold as it could be and it was still hotter than I would usually have it.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Bed was hard and sheets were rough.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: I loved that there was a coffee shop\n",
            "underneath, and it closed at 12am every night, so that I can get my late\n",
            "night coffee, if I wanted.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Dimly lit.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The towels had holes in them.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The hotel  advertised AC as one of its amenities in its booking.com descriptions!\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The bed was super comfortable and the bathtub with jets was awesome too.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: We actually enjoyed how small our room was because we knew about it ahead of time and wanted to try something really different.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Bedding was changed once,\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The same counts for the bathroom, especially the shower was great.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: The hotel has a rooftop with a hot tub which has an awesome view.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: It was quiet.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Rooms are small,\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The drapes could have fit the window.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: It was very not comfortable.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Facilities were great.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Just one bed so in your room you always have to sit on the bed.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: So there could have been more convenient outlets.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The exercise room closest to my floor was filled with big screen TVs and sheets covering them.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: a bit tight to make people either pay or leave yr room.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Shower was intense.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The bed was very comfortable, and room minimalist\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Rooms aren't very sound proof from hallway sounds.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Cool design.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Our room was very spacious, especially for NYC.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: The main lobby is nice\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Carpets are coming unstitched.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: It was bigger so that was nice!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Room was not cleaned even once during our stay.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Room not what we ordered or prepaid for.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The room needed to be painted,\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Sep 5-8 room 302\n",
            "Room was too small, the shower pressure was good.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Very large for Manhattan with good sized bed, flat screen TV & ample closet.\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: #NAME?\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Waited over 40 minutes to use shower.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: The lifts worked!\n",
            "Overall sentiment: positive\n",
            "\n",
            "Text: Elevators tend to be slow...\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: Crumbs from snacks were not cleaned up for 3 days!!\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: the bathroom was a little dirty with hair at the walls\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: We had requested two queen beds and got a room with 1 queen and 2 twins, we were advised that there were not any other rooms and could put the (2) beds together, which we did and it was no issue as far as sleeping.\n",
            "Overall sentiment: neutral\n",
            "\n",
            "Text: Noisy noisy suite on 4th floor.\n",
            "Overall sentiment: negative\n",
            "\n",
            "Text: no way to lock the door.\n",
            "Overall sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"\n",
        "]\n",
        "\n",
        "result = client.analyze_sentiment(message)[0]\n",
        "print(\"Sentiment:\", result.sentiment)\n",
        "print(\"Confidence Scores:\", result.confidence_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WS2fwC7Whr9",
        "outputId": "b30dab5f-1833-45cd-965c-d0e3cbd708bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive\n",
            "Confidence Scores: {'positive': 0.87, 'neutral': 0.13, 'negative': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHP3DDxGWzO5",
        "outputId": "acdfcc26-82e8-4eff-97af-fc8cbc16ee4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCOVAfAZoqZ",
        "outputId": "b93295e2-5791-40b5-f2f7-08e633249f35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwAvmAOw0HOR",
        "outputId": "1f60a4d5-6821-4cea-b33e-c982c2776d47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade --force-reinstall gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C24DDwnyafFk",
        "outputId": "3f43d306-f45e-4604-816e-17f8f468d348"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "smart_open",
                  "wrapt"
                ]
              },
              "id": "b3507d03c7654346a2801c99d9e04e05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# === Încărcare fișier CSV\n",
        "crtDir = os.getcwd()\n",
        "fileName = os.path.join(crtDir, 'data', 'reviews_mixed.csv')\n",
        "texts, labels = [], []\n",
        "\n",
        "with open(fileName, encoding='utf-8') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    headers = next(reader)\n",
        "    text_idx = headers.index(\"Text\")\n",
        "    label_idx = headers.index(\"Sentiment\")\n",
        "    for row in reader:\n",
        "        texts.append(row[text_idx])\n",
        "        labels.append(row[label_idx])\n",
        "\n",
        "# antrenare si test\n",
        "trainInputs, testInputs, trainOutputs, testOutputs = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
        "trainTFIDF = tfidf_vectorizer.fit_transform(trainInputs)\n",
        "testTFIDF = tfidf_vectorizer.transform(testInputs)\n",
        "\n",
        "#Word2Vec\n",
        "tokenized_train = [t.lower().split() for t in trainInputs]\n",
        "tokenized_test = [t.lower().split() for t in testInputs]\n",
        "w2v_model = Word2Vec(sentences=tokenized_train, vector_size=50, window=5, min_count=1)\n",
        "\n",
        "def vectorize_w2v(tokenized_texts, model):\n",
        "    vecs = []\n",
        "    for tokens in tokenized_texts:\n",
        "        valid = [model.wv[t] for t in tokens if t in model.wv]\n",
        "        vecs.append(np.mean(valid, axis=0) if valid else np.zeros(model.vector_size))\n",
        "    return np.array(vecs)\n",
        "\n",
        "trainW2V = vectorize_w2v(tokenized_train, w2v_model)\n",
        "testW2V = vectorize_w2v(tokenized_test, w2v_model)\n",
        "\n",
        "#alte caracteristici: nr cuvinte, lungime text, nr !\n",
        "def custom_features(texts):\n",
        "    return np.array([[len(t.split()), len(t), t.count('!')] for t in texts])\n",
        "\n",
        "trainCustom = custom_features(trainInputs)\n",
        "testCustom = custom_features(testInputs)\n",
        "\n",
        "#Combinare caracteristici\n",
        "trainCombined = hstack([trainTFIDF, trainW2V, trainCustom])\n",
        "testCombined = hstack([testTFIDF, testW2V, testCustom])\n",
        "\n",
        "#Transformare etichete\n",
        "encoder = LabelEncoder()\n",
        "trainLabels = encoder.fit_transform(trainOutputs)\n",
        "testLabels = encoder.transform(testOutputs)\n",
        "\n",
        "#ann\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=trainCombined.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(trainCombined.toarray(), trainLabels, epochs=10, batch_size=16, verbose=1)\n",
        "\n",
        "#Evaluare\n",
        "loss, acc = model.evaluate(testCombined.toarray(), testLabels)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "#predictie pentru mesajul dat\n",
        "msg = [\"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"]\n",
        "msg_tfidf = tfidf_vectorizer.transform(msg)\n",
        "msg_w2v = vectorize_w2v([msg[0].lower().split()], w2v_model)\n",
        "msg_custom = custom_features(msg)\n",
        "msg_combined = hstack([msg_tfidf, msg_w2v, msg_custom])\n",
        "\n",
        "prediction = model.predict(msg_combined.toarray()).argmax()\n",
        "predicted_label = encoder.inverse_transform([prediction])[0]\n",
        "\n",
        "print(\"Predicted Sentiment:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHl49q3PZaYx",
        "outputId": "afaff9c7-307b-456a-8b45-a1914abda021"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6382 - loss: 0.8534\n",
            "Epoch 2/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6127 - loss: 1.1140 \n",
            "Epoch 3/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.9826 \n",
            "Epoch 4/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6154 - loss: 0.8531 \n",
            "Epoch 5/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.7120 \n",
            "Epoch 6/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.7208 \n",
            "Epoch 7/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6401 - loss: 0.6829 \n",
            "Epoch 8/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6371 - loss: 0.7084 \n",
            "Epoch 9/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.7431 \n",
            "Epoch 10/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6706 - loss: 0.7962 \n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7103 - loss: 0.6617 \n",
            "Test accuracy: 69.05%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import hstack\n"
      ],
      "metadata": {
        "id": "R0CeYbjycjjB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functie de activare ReLU\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Derivata functiei ReLU\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "# Functie de activare Softmax\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # stabilizare numerica\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Derivata Softmax pentru backpropagation\n",
        "def softmax_derivative(output, y):\n",
        "    return output - y\n"
      ],
      "metadata": {
        "id": "xeqHA8g7cvtW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cod propriu ann"
      ],
      "metadata": {
        "id": "Z47AK0opvhdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.W1 = np.random.randn(self.input_dim, self.hidden_dim) * 0.01\n",
        "        self.b1 = np.zeros((1, self.hidden_dim))\n",
        "\n",
        "        self.W2 = np.random.randn(self.hidden_dim, self.output_dim) * 0.01\n",
        "        self.b2 = np.zeros((1, self.output_dim))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Propagare inainte (forward pass)\n",
        "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.A1 = relu(self.Z1)  # Strat ascuns\n",
        "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "        self.A2 = softmax(self.Z2)  # Strat de iesire (Softmax)\n",
        "        return self.A2\n",
        "\n",
        "    def backward(self, X, y, learning_rate=0.01):\n",
        "        # Calcularea erorii si actualizarea greutatilor (backpropagation)\n",
        "\n",
        "        m = X.shape[0]  # Dimensiunea lotului de antrenament\n",
        "\n",
        "        # Calcularea gradientului pentru stratul de iesire\n",
        "        dZ2 = softmax_derivative(self.A2, y)\n",
        "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Calcularea gradientului pentru stratul ascuns\n",
        "        dA1 = np.dot(dZ2, self.W2.T)\n",
        "        dZ1 = dA1 * relu_derivative(self.Z1)\n",
        "        dW1 = np.dot(X.T, dZ1) / m\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Actualizarea greutatilor\n",
        "        self.W1 -= learning_rate * dW1\n",
        "        self.b1 -= learning_rate * db1\n",
        "        self.W2 -= learning_rate * dW2\n",
        "        self.b2 -= learning_rate * db2\n"
      ],
      "metadata": {
        "id": "xX9kV_93cx54"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcția de antrenare\n",
        "def train(model, X_train, y_train, epochs=1000, learning_rate=0.01):\n",
        "    for epoch in range(epochs):\n",
        "        model.forward(X_train)\n",
        "        model.backward(X_train, y_train, learning_rate)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            loss = -np.mean(np.log(model.A2[np.arange(y_train.shape[0]), np.argmax(y_train, axis=1)]))\n",
        "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Funcția de predicție\n",
        "def predict(model, X):\n",
        "    output = model.forward(X)\n",
        "    return np.argmax(output, axis=1)\n"
      ],
      "metadata": {
        "id": "4JMWW6BOczu0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Încărcarea datelor din fișier CSV\n",
        "fileName = os.path.join(os.getcwd(), 'data', 'reviews_mixed.csv')\n",
        "texts, labels = [], []\n",
        "\n",
        "with open(fileName, encoding='utf-8') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    headers = next(reader)\n",
        "    text_idx = headers.index(\"Text\")\n",
        "    label_idx = headers.index(\"Sentiment\")\n",
        "    for row in reader:\n",
        "        texts.append(row[text_idx])\n",
        "        labels.append(row[label_idx])\n",
        "\n",
        "# Împărțirea datelor în seturi de antrenare și test\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocesarea textelor (TF-IDF și alte caracteristici personalizate)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Crearea unui encoder pentru etichete\n",
        "encoder = LabelEncoder()\n",
        "y_train_enc = encoder.fit_transform(y_train)\n",
        "y_test_enc = encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding pentru etichetele de ieșire\n",
        "y_train_onehot = np.eye(len(encoder.classes_))[y_train_enc]\n",
        "y_test_onehot = np.eye(len(encoder.classes_))[y_test_enc]\n",
        "\n",
        "# Alte trăsături (număr de cuvinte, lungime text, nr. de semne de exclamare)\n",
        "def custom_features(texts):\n",
        "    return np.array([[len(t.split()), len(t), t.count('!')] for t in texts])\n",
        "\n",
        "X_train_custom = custom_features(X_train)\n",
        "X_test_custom = custom_features(X_test)\n",
        "\n",
        "# Combinarea trăsăturilor\n",
        "X_train_combined = np.hstack([X_train_tfidf, X_train_custom])\n",
        "X_test_combined = np.hstack([X_test_tfidf, X_test_custom])\n"
      ],
      "metadata": {
        "id": "Uf5ZtgyTc1U9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearea unui model ANN\n",
        "model = ANN(input_dim=X_train_combined.shape[1], hidden_dim=128, output_dim=len(encoder.classes_))\n",
        "\n",
        "# Antrenarea modelului\n",
        "train(model, X_train_combined, y_train_onehot, epochs=1000, learning_rate=0.01)\n",
        "\n",
        "# Evaluarea modelului pe setul de test\n",
        "y_pred = predict(model, X_test_combined)\n",
        "\n",
        "# Calcularea acurateței\n",
        "accuracy = np.mean(y_pred == np.argmax(y_test_onehot, axis=1))\n",
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Predicție pentru un mesaj dat\n",
        "msg = [\"By choosing a bike over a car, I’m reducing my environmental footprint.\"]\n",
        "msg_tfidf = tfidf_vectorizer.transform(msg).toarray()\n",
        "msg_custom = custom_features(msg)\n",
        "msg_combined = np.hstack([msg_tfidf, msg_custom])\n",
        "\n",
        "pred = predict(model, msg_combined)\n",
        "predicted_label = encoder.inverse_transform(pred)[0]\n",
        "print(f\"Predicted Sentiment: {predicted_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtA7qrknc3lV",
        "outputId": "801f4410-b348-4493-b267-9a8741dec533"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6764\n",
            "Epoch 100, Loss: 0.6353\n",
            "Epoch 200, Loss: 0.6328\n",
            "Epoch 300, Loss: 0.6309\n",
            "Epoch 400, Loss: 0.6293\n",
            "Epoch 500, Loss: 0.6280\n",
            "Epoch 600, Loss: 0.6269\n",
            "Epoch 700, Loss: 0.6259\n",
            "Epoch 800, Loss: 0.6250\n",
            "Epoch 900, Loss: 0.6240\n",
            "Test accuracy: 71.43%\n",
            "Predicted Sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to compute softmax (normalized between 0 and 1)\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "# Cross-entropy loss calculation\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-8)) / y_true.shape[0]\n",
        "\n",
        "class MultiClassANN:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights_input_hidden = np.random.randn(input_dim, hidden_dim)\n",
        "        self.bias_hidden = np.zeros((1, hidden_dim))\n",
        "        self.weights_hidden_output = np.random.randn(hidden_dim, output_dim)\n",
        "        self.bias_output = np.zeros((1, output_dim))\n",
        "\n",
        "    # Forward pass through the network\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.a1 = np.tanh(self.z1)  # Hidden layer activation\n",
        "        self.z2 = np.dot(self.a1, self.weights_hidden_output) + self.bias_output\n",
        "        self.a2 = softmax(self.z2)  # Output layer activation\n",
        "        return self.a2\n",
        "\n",
        "    # Backward pass for gradient calculation and weight updates\n",
        "    def backward(self, X, y_true, y_pred):\n",
        "        d_z2 = y_pred - y_true\n",
        "        d_weights_hidden_output = np.dot(self.a1.T, d_z2)\n",
        "        d_bias_output = np.sum(d_z2, axis=0, keepdims=True)\n",
        "\n",
        "        d_a1 = np.dot(d_z2, self.weights_hidden_output.T)\n",
        "        d_z1 = d_a1 * (1 - np.tanh(self.z1) ** 2)  # Derivative of tanh activation\n",
        "        d_weights_input_hidden = np.dot(X.T, d_z1)\n",
        "        d_bias_hidden = np.sum(d_z1, axis=0, keepdims=True)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output -= self.learning_rate * d_weights_hidden_output\n",
        "        self.bias_output -= self.learning_rate * d_bias_output\n",
        "        self.weights_input_hidden -= self.learning_rate * d_weights_input_hidden\n",
        "        self.bias_hidden -= self.learning_rate * d_bias_hidden\n",
        "\n",
        "    # Training function with specified epochs\n",
        "    def train(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            loss = cross_entropy(y, y_pred)\n",
        "            self.backward(X, y, y_pred)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch} - Loss: {loss:.4f}\")\n",
        "\n",
        "    # Prediction function\n",
        "    def predict(self, X):\n",
        "        probs = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "# Preprocessing the message and predicting sentiment/emotion\n",
        "def predict_emotion(message, model, word2vec_model, label_encoder):\n",
        "    # Assuming preprocess_text and compute_features are defined elsewhere\n",
        "    # and that word2vec_model is a trained Word2Vec model\n",
        "    processed_message = preprocess_text(message)\n",
        "    message_vector = compute_features(word2vec_model, [processed_message])\n",
        "    prediction_index = model.predict(np.array(message_vector))[0]\n",
        "    predicted_emotion = label_encoder.inverse_transform([prediction_index])[0]\n",
        "    return predicted_emotion\n",
        "\n",
        "# Load data\n",
        "fileName = os.path.join(os.getcwd(), 'data', 'reviews_mixed.csv')\n",
        "texts, labels = [], []\n",
        "\n",
        "with open(fileName, encoding='utf-8') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    headers = next(reader)\n",
        "    text_idx = headers.index(\"Text\")\n",
        "    label_idx = headers.index(\"Sentiment\")\n",
        "    for row in reader:\n",
        "        texts.append(row[text_idx])\n",
        "        labels.append(row[label_idx])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Word2Vec model\n",
        "tokenized_train = [t.lower().split() for t in X_train]\n",
        "word2vec_model = Word2Vec(sentences=tokenized_train, vector_size=50, window=5, min_count=1)\n",
        "\n",
        "# Create LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_balanced = label_encoder.fit_transform(y_train)  # Assuming y_train is balanced\n",
        "\n",
        "# Define compute_features (replace with your actual feature computation)\n",
        "def compute_features(word2vec_model, texts):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        tokens = text.lower().split()\n",
        "        valid_tokens = [word2vec_model.wv[t] for t in tokens if t in word2vec_model.wv]\n",
        "        text_feature = np.mean(valid_tokens, axis=0) if valid_tokens else np.zeros(word2vec_model.vector_size)\n",
        "        features.append(text_feature)\n",
        "    return features\n",
        "\n",
        "# Compute features\n",
        "train_features_balanced = compute_features(word2vec_model, X_train)\n",
        "test_features = compute_features(word2vec_model, X_test)\n",
        "\n",
        "# Define preprocess_text (replace with your actual text preprocessing)\n",
        "def preprocess_text(text):\n",
        "    return text.lower()  # Example: lowercasing\n",
        "\n",
        "# Initialize and train the model\n",
        "model = MultiClassANN(input_dim=word2vec_model.vector_size, hidden_dim=128, output_dim=len(label_encoder.classes_))\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "one_hot_labels = np.eye(len(label_encoder.classes_))[train_labels_balanced]\n",
        "\n",
        "# Train on balanced dataset\n",
        "model.train(np.array(train_features_balanced), one_hot_labels, epochs=1000)\n",
        "\n",
        "# Evaluate accuracy on test set\n",
        "predictions = model.predict(np.array(test_features))\n",
        "true_labels = label_encoder.transform(y_test)  # Transform y_test using the same encoder\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Test accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print predicted emotions in text\n",
        "predicted_texts = label_encoder.inverse_transform(predictions)\n",
        "print(f\"Predictions (text): {predicted_texts}\")\n",
        "\n",
        "# Predict emotion for a new message\n",
        "new_message = \"By choosing a bike over a car, I’m reducing my environmental footprint. Cycling promotes eco-friendly transportation, and I’m proud to be part of that movement.\"\n",
        "predicted_feeling = predict_emotion(new_message, model, word2vec_model, label_encoder)\n",
        "print(f\"Predicted emotion: {predicted_feeling}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJb1Y7XIeuKa",
        "outputId": "dc5692c4-b6f4-4a3c-c17d-588d29467a14"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Loss: 0.6894\n",
            "Epoch 100 - Loss: 5.3311\n",
            "Epoch 200 - Loss: 3.1127\n",
            "Epoch 300 - Loss: 5.9169\n",
            "Epoch 400 - Loss: 1.8478\n",
            "Epoch 500 - Loss: 8.3214\n",
            "Epoch 600 - Loss: 5.9169\n",
            "Epoch 700 - Loss: 5.8522\n",
            "Epoch 800 - Loss: 5.9169\n",
            "Epoch 900 - Loss: 5.9109\n",
            "Test accuracy: 0.71\n",
            "Predictions (text): ['negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative']\n",
            "Predicted emotion: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(\"Distribuția etichetelor în setul de antrenament:\", Counter(y_train))\n",
        "print(\"Distribuția etichetelor în setul de test:\", Counter(y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4bsuiqKLyxuB",
        "outputId": "ea3d9b49-4860-441f-b633-5bb55de42c95"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf7927659c18>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribuția etichetelor în setul de antrenament:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Distribuția etichetelor în setul de test:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    }
  ]
}